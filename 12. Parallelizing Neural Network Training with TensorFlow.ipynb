{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelizing Neural Network\n",
    "Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  This chapter begins the next stage of our journey into training machine learning and\n",
    "#### deep learning, and we'll explore the following topics:\n",
    "\n",
    "    . How TensorFlow improves training performance\n",
    "    . Working with TensorFlow to write optimized machine learning code\n",
    "    . Using TensorFlow high-level APIs to build a multilayer neural network\n",
    "    . Choosing activation functions for artificial neural networks\n",
    "    . Introducing Keras, a high-level wrapper around TensorFlow, for\n",
    "        implementing common deep learning architectures most conveniently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pip install tensorflow\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= 1.0 --> z= 2.7\n",
      "x= 0.6 --> z= 1.9\n",
      "x=-1.8 --> z=-2.9\n"
     ]
    }
   ],
   "source": [
    "# # Create a grap\n",
    "# g = tf.Graph()\n",
    "# with g.as_default():\n",
    "#     x = tf.placeholder(dtype=tf.float32,\n",
    "#                        shape=(None), name='x')\n",
    "#     w = tf.variable(2.0, name='weight')\n",
    "#     b = tf.variable(0.7, name='bias')\n",
    "#     z = w*x + b\n",
    "\n",
    "#     init = tf.global_variables_initializer()\n",
    "\n",
    "# # Create a session and pass in graph g\n",
    "# with tf.session(graph=g) as sess:\n",
    "#     # Initialize all variables\n",
    "#     sess.run(init)\n",
    "#     # Print z given some input x\n",
    "#     for t in [1.0, 0.6, -1.8]:\n",
    "#         print('x=%4.1f --> z=%4.1f'%(t, sess.run(z, feed_dict={x:t})))\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create variables\n",
    "w = tf.Variable(2.0, name='weight')\n",
    "b = tf.Variable(0.7, name='bias')\n",
    "\n",
    "# Define a function for the computation\n",
    "@tf.function\n",
    "def compute_z(x):\n",
    "    z = w * x + b\n",
    "    return z\n",
    "\n",
    "# Initialize variables\n",
    "w.assign(2.0)\n",
    "b.assign(0.7)\n",
    "\n",
    "# Run the computation\n",
    "for t in [1.0, 0.6, -1.8]:\n",
    "    z = compute_z(t)\n",
    "    print('x=%4.1f --> z=%4.1f' % (t, z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Developing simple model with the low-level Tensorflow api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]] [1.  1.3 3.1 2.  5.  6.3 6.6 7.4 8.  9. ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "\n",
    "X_train = np.arange(10).reshape((10, 1))\n",
    "y_train = np.array([1.0, 1.3, 3.1,2.0, 5.0, 6.3, 6.6, 7.4, 8.0, 9.0])\n",
    "\n",
    "print(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfLinreg(object):\n",
    "    def __init__(self, x_dim, learning_rate=0.01, random_seed=None):\n",
    "        self.x_dim = x_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.g = tf.Graph()\n",
    "\n",
    "        # Build the model\n",
    "        with self.g.as_default():\n",
    "            ## set graph-level random_seed\n",
    "            tf.random.set_seed(random_seed)\n",
    "\n",
    "    def build(self):\n",
    "            ## Create initializer\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "    def build(self):\n",
    "        ## define placeholders for  input \n",
    "        self.X = tf.keras.Input(shape=(None, self.x_dim), name='x_input')\n",
    "        self.y = tf.keras.Input(shape=(None,), name='y_input')\n",
    "\n",
    "        print(self.X)\n",
    "        print(self.y)\n",
    "        ## define weight matrix and bias vector\n",
    "        w = tf.Variable(tf.zeros(shape=(1)), name='weight')\n",
    "        b = tf.Variable(tf.zeros(shape=(1)), name='bias')\n",
    "\n",
    "        print(w)\n",
    "        print(b)\n",
    "\n",
    "        ## define model operations\n",
    "        self.z_net = tf.squeeze(w * self.X + b, name='z_net')\n",
    "        print(self.z_net)\n",
    "\n",
    "        sqr_errors = tf.square(self.y - self.z_net,name='sqr_errors')\n",
    "        print(sqr_errors)\n",
    "        \n",
    "        self.mean_cost = tf.reduce_mean(sqr_errors,name='mean_cost')\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate,name='GradientDescent')\n",
    "        \n",
    "        self.optimizer = optimizer.minimize(self.mean_cost)\n",
    "lrmodel = TfLinreg(x_dim=X_train.shape[1], learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_linreg(model, X_train, y_train, num_epochs=10):\n",
    "    # Initialize all variables: W and b\n",
    "\n",
    "    # List to store the training costs\n",
    "    training_costs = []\n",
    "    \n",
    "    # Training loop for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Use a GradientTape for automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(X_train, training=True)\n",
    "            cost = model.mean_cost(y_train, predictions)\n",
    "        \n",
    "        # Compute gradients and apply them\n",
    "        gradients = tape.gradient(cost, model.trainable_variables)\n",
    "        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Append the cost to the training_costs list\n",
    "        training_costs.append(cost.numpy())\n",
    "    \n",
    "    # Return the list of training costs\n",
    "    return training_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TfLinreg' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_linreg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlrmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m, in \u001b[0;36mtrain_linreg\u001b[1;34m(model, X_train, y_train, num_epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Use a GradientTape for automatic differentiation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 11\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         cost \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmean_cost(y_train, predictions)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Compute gradients and apply them\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TfLinreg' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "train_linreg(lrmodel, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building multilayer neural networks using\n",
    "TensorFlow's Layers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"Load MNIST data from 'path' \"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) -.5) * 2\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"\n",
    "    Load MNIST data from `path`.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The directory containing the MNIST data files.\n",
    "    kind (str): Either 'train' or 't10k' to specify training or test data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - images (np.ndarray): The image data as a 2D numpy array of shape (num_samples, 784).\n",
    "        - labels (np.ndarray): The labels as a 1D numpy array of shape (num_samples,).\n",
    "    \"\"\"\n",
    "    # Paths to the labels and images files\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte')\n",
    "\n",
    "    # Load labels\n",
    "    try:\n",
    "        with open(labels_path, 'rb') as lbpath:\n",
    "            magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "            labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Labels file not found at {labels_path}\") from e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading labels file: {e}\") from e\n",
    "\n",
    "    # Load images\n",
    "    try:\n",
    "        with open(images_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "            images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), rows * cols)\n",
    "            images = ((images / 255.) - 0.5) * 2  # Normalize to [-1, 1]\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Images file not found at {images_path}\") from e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading images file: {e}\") from e\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Example usage:\n",
    "# path = 'path/to/mnist/dataset'\n",
    "# images, labels = load_mnist(path, kind='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error reading labels file: [Errno 13] Permission denied: './mnist/train-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mload_mnist\u001b[1;34m(path, kind)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m lbpath:\n\u001b[0;32m     25\u001b[0m         magic, n \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>II\u001b[39m\u001b[38;5;124m'\u001b[39m, lbpath\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Nazbeen-Ai\\Documents\\My Projects\\Machine Learning Projects\\Python Machine Learning Second Edition\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './mnist/train-labels-idx1-ubyte'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./mnist/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRows: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Columns: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[27], line 30\u001b[0m, in \u001b[0;36mload_mnist\u001b[1;34m(path, kind)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading labels file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Load images\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error reading labels file: [Errno 13] Permission denied: './mnist/train-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('./mnist/', kind='train')\n",
    "print('Rows: %d, Columns: %d' %(X_train.shape[0],X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
